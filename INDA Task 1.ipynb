{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2258190-a45c-4676-b348-a2a874133acd",
   "metadata": {},
   "source": [
    "# Task One -- Sentiment Analysis (FiQA SA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31172726-be27-4dd4-95a3-5cf69107bcfb",
   "metadata": {},
   "source": [
    "## Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c77dc957-6515-46fd-9df3-6b4d894c5ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mdatasets\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_dataset \u001B[38;5;66;03m# Doesn't work on PyCharm\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_selection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_test_split\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfeature_extraction\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtext\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CountVectorizer\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'datasets'"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset # Doesn't work on PyCharm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "import reprlib\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.matutils import any2sparse\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0175e53-6567-4b29-99b1-baa40d4d7ee7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Importing the Training Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eaf1ffb-b5ce-4a3e-93a1-91a20385381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [\"data_cache/FiQA_ABSA_task1/task1_headline_ABSA_train.json\",\n",
    "               \"data_cache/FiQA_ABSA_task1/task1_post_ABSA_train.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "422d1622-0ff6-45ae-b225-a66a87900ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of instances: 1111\n",
      "Number of labels: 1111\n",
      "Number of negative labels: 310\n",
      "Number of neutral labels: 195\n",
      "Number of positive labels: 606\n"
     ]
    }
   ],
   "source": [
    "def load_fiqa_sa_from_json(json_files):\n",
    "    train_text = []\n",
    "    train_labels = []\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, \"r\", encoding=\"utf-8\") as handle:  # UTF-8 is needed to prevent a UnicodeDecodeError I recieved\n",
    "            dataf = json.load(handle)\n",
    "\n",
    "        dataf_text = [dataf[k][\"sentence\"] for k in dataf.keys()]\n",
    "        # print(len(dataf_text))\n",
    "        train_text.extend(dataf_text)\n",
    "\n",
    "        dataf_labels = [float(dataf[k][\"info\"][0][\"sentiment_score\"]) for k in dataf.keys()]\n",
    "        # print(len(dataf_labels))\n",
    "        train_labels.extend(dataf_labels)\n",
    "\n",
    "    train_text = np.array(train_text)\n",
    "    train_labels = np.array(train_labels)\n",
    "    \n",
    "    return train_text, train_labels\n",
    "\n",
    "\n",
    "def threshold_scores(scores):\n",
    "    \"\"\"\n",
    "    Convert sentiment scores to discrete labels.\n",
    "    0 = negative.\n",
    "    1 = neutral.\n",
    "    2 = positive.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for score in scores:\n",
    "        if score < -0.2:\n",
    "            labels.append(0)\n",
    "        elif score > 0.2:\n",
    "            labels.append(2)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "            \n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "all_text, all_labels = load_fiqa_sa_from_json(train_files)\n",
    "    \n",
    "print(f\"Number of instances: {len(all_text)}\")\n",
    "print(f\"Number of labels: {len(all_labels)}\")\n",
    "\n",
    "all_labels = threshold_scores(all_labels)\n",
    "print(f\"Number of negative labels: {np.sum(all_labels==0)}\")\n",
    "print(f\"Number of neutral labels: {np.sum(all_labels==1)}\")\n",
    "print(f\"Number of positive labels: {np.sum(all_labels==2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcda60a-6871-4c7c-851e-aff0d51eea9b",
   "metadata": {},
   "source": [
    "## Creating the Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bef424c5-d3e7-4e24-b51d-b82a823d3868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training instances = 754\n",
      "Number of validation instances = 134\n",
      "Number of test instances = 223\n",
      "\n",
      "What does one instance look like from the training set?:\n",
      "Barclays appoints JPMorgan's Paul Compton as new COO\n",
      "...and here is its corresponding sentiment label: 1\n"
     ]
    }
   ],
   "source": [
    "# Split test data from training data\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(\n",
    "    all_text, \n",
    "    all_labels, \n",
    "    test_size=0.2, \n",
    "    stratify=all_labels)  # make sure the same proportion of labels is in the test set and training set\n",
    "\n",
    "# Split validation data from training data\n",
    "train_documents, val_documents, train_labels, val_labels = train_test_split(\n",
    "    train_documents, \n",
    "    train_labels, \n",
    "    test_size=0.15, \n",
    "    stratify=train_labels)  # make sure the same proportion of labels is in the test set and training set\n",
    "\n",
    "print(f\"Number of training instances = {len(train_documents)}\")\n",
    "print(f\"Number of validation instances = {len(val_documents)}\")\n",
    "print(f\"Number of test instances = {len(test_documents)}\")\n",
    "\n",
    "print(f\"\\nWhat does one instance look like from the training set?:\\n{train_documents[234]}\")\n",
    "print(f\"...and here is its corresponding sentiment label: {train_labels[234]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41efc92-c6d8-435f-819e-2d1a632522ce",
   "metadata": {},
   "source": [
    "## Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2426b82-1db7-46dc-8962-f1d849eee28b",
   "metadata": {},
   "source": [
    "### Tokenizing, Stop Word Removal, Case Folding, and Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "055a1f12-69d0-43cf-a5a2-1466ca62075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5ef5328c-0723-4b1c-8bc0-d3d08ca8fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\misha\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\misha\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Define the stop words\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __call__(self, documents):\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        return [lemmatizer.lemmatize(word.lower()) for word in word_tokenize(documents)]\n",
    "    \n",
    "vectorizer_Lem = CountVectorizer(tokenizer=LemmaTokenizer(), stop_words='english')\n",
    "\n",
    "vectorizer_Lem.fit(train_documents)  # Learn the vocabulary\n",
    "X_train_Lem = vectorizer_Lem.transform(train_documents) # extract training set bags of words\n",
    "X_val_Lem = vectorizer_Lem.transform(val_documents) # extract validation set bags of words\n",
    "X_test_Lem = vectorizer_Lem.transform(test_documents)  # extract test set bags of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f5ad734-2d1b-46b2-bd29-6f68a4e04550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size = 2953\n"
     ]
    }
   ],
   "source": [
    "vocabulary_Lem = vectorizer_Lem.vocabulary_\n",
    "print(f\"Vocabulary size = {len(vocabulary_Lem)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28470e85-a42d-4d4f-b72b-ffc437351c66",
   "metadata": {},
   "source": [
    "### Tokenizing, Stop Word Removal, Case Folding, and no Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "707bbb01-5e01-4fd5-8d06-4cf41db6c61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the stop words\n",
    "stopwords_list = stopwords.words(\"english\")\n",
    "\n",
    "class Tokenizer(object):\n",
    "    def __call__(self, documents):\n",
    "        return word_tokenize(documents.lower())\n",
    "\n",
    "vectorizer = CountVectorizer(tokenizer=Tokenizer(), stop_words='english')\n",
    "\n",
    "vectorizer.fit(train_documents)  # Learn the vocabulary\n",
    "X_train = vectorizer.transform(train_documents) # extract training set bags of words\n",
    "X_val = vectorizer.transform(val_documents) # extract validation set bags of words\n",
    "X_test = vectorizer.transform(test_documents)  # extract test set bags of words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5019ea-7d79-4280-a0ff-208b6374d991",
   "metadata": {},
   "source": [
    "## Applying Naive Bayes to Lem set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e78e42c3-8241-4933-b951-53006272ce24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the classifier\n",
    "classifier_Lem = MultinomialNB()\n",
    "\n",
    "# Training the classifier\n",
    "classifier_Lem.fit(X_train_Lem, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "47d52117-5797-4116-af0f-27e2cf43cc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the classifier\n",
    "y_val_pred_Lem = classifier_Lem.predict(X_test_Lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f972d1f-ae04-48ba-bf39-69ec66cc3774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.672645739910314\n",
      "Precision (macro average) = 0.6912606127722407\n",
      "Recall (macro average) = 0.5362038807305862\n",
      "F1 score (micro average) = 0.672645739910314\n",
      "F1 score (macro average) = 0.5551949515438359\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.45      0.53        62\n",
      "           1       0.75      0.23      0.35        39\n",
      "           2       0.67      0.93      0.78       122\n",
      "\n",
      "    accuracy                           0.67       223\n",
      "   macro avg       0.69      0.54      0.56       223\n",
      "weighted avg       0.68      0.67      0.64       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_lem = accuracy_score(test_labels, y_val_pred_Lem)\n",
    "print(f'Accuracy = {acc_lem}')\n",
    "\n",
    "prec_lem = precision_score(test_labels, y_val_pred_Lem, average='macro')\n",
    "print(f'Precision (macro average) = {prec_lem}')\n",
    "\n",
    "rec_lem = recall_score(test_labels, y_val_pred_Lem, average='macro')\n",
    "print(f'Recall (macro average) = {rec_lem}')\n",
    "\n",
    "f1_micro_lem = f1_score(test_labels, y_val_pred_Lem, average='micro')\n",
    "print(f'F1 score (micro average) = {f1_micro_lem}')\n",
    "\n",
    "f1_macro_lem = f1_score(test_labels, y_val_pred_Lem, average='macro')\n",
    "print(f'F1 score (macro average) = {f1_macro_lem}')\n",
    "\n",
    "# We can get all of these with a per-class breakdown using classification_report:\n",
    "print(classification_report(test_labels, y_val_pred_Lem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308d213-f2a8-43d1-a0e7-f8b386d6095d",
   "metadata": {},
   "source": [
    "## Applying Naive Bayes to non Lem set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f7d5964e-7713-4d4f-b8ae-1448620c0336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the classifier\n",
    "classifier = MultinomialNB()\n",
    "\n",
    "# Training the classifier\n",
    "classifier.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22e5d098-0cbf-4ca8-a1ef-8f6c306096bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the classifier\n",
    "y_val_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "510907bd-38f2-453e-a97d-278e5b6be89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6547085201793722\n",
      "Precision (macro average) = 0.6726178190574474\n",
      "Recall (macro average) = 0.5263280406062003\n",
      "F1 score (micro average) = 0.6547085201793722\n",
      "F1 score (macro average) = 0.549227126670049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.39      0.48        62\n",
      "           1       0.73      0.28      0.41        39\n",
      "           2       0.65      0.91      0.76       122\n",
      "\n",
      "    accuracy                           0.65       223\n",
      "   macro avg       0.67      0.53      0.55       223\n",
      "weighted avg       0.66      0.65      0.62       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(test_labels, y_val_pred)\n",
    "print(f'Accuracy = {acc}')\n",
    "\n",
    "prec = precision_score(test_labels, y_val_pred, average='macro')\n",
    "print(f'Precision (macro average) = {prec}')\n",
    "\n",
    "rec = recall_score(test_labels, y_val_pred, average='macro')\n",
    "print(f'Recall (macro average) = {rec}')\n",
    "\n",
    "f1_micro = f1_score(test_labels, y_val_pred, average='micro')\n",
    "print(f'F1 score (micro average) = {f1_micro}')\n",
    "\n",
    "f1_macro = f1_score(test_labels, y_val_pred, average='macro')\n",
    "print(f'F1 score (macro average) = {f1_macro}')\n",
    "\n",
    "# We can get all of these with a per-class breakdown using classification_report:\n",
    "print(classification_report(test_labels, y_val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5fdda4-cc3d-4930-be2d-f184ae4bf567",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression to Lem set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30511b61-51f5-4428-9be8-bb831784e76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the classifier\n",
    "logi_classifier_Lem = LogisticRegression()\n",
    "\n",
    "# Training the classifier\n",
    "logi_classifier_Lem.fit(X_train_Lem, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8567d3f0-127c-4a1c-9c35-aef0399c38c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the classifier\n",
    "y_val_pred_logi_Lem = logi_classifier_Lem.predict(X_test_Lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c4d18bf-a978-4402-9f70-b1046ef955fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.672645739910314\n",
      "Precision (macro average) = 0.6430648692598058\n",
      "Recall (macro average) = 0.5525950634358884\n",
      "F1 score (micro average) = 0.672645739910314\n",
      "F1 score (macro average) = 0.5693043273688435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.52      0.58        62\n",
      "           1       0.59      0.26      0.36        39\n",
      "           2       0.69      0.89      0.77       122\n",
      "\n",
      "    accuracy                           0.67       223\n",
      "   macro avg       0.64      0.55      0.57       223\n",
      "weighted avg       0.66      0.67      0.65       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_logi_lem = accuracy_score(test_labels, y_val_pred_logi_Lem)\n",
    "print(f'Accuracy = {acc_logi_lem}')\n",
    "\n",
    "prec_logi_lem = precision_score(test_labels, y_val_pred_logi_Lem, average='macro')\n",
    "print(f'Precision (macro average) = {prec_logi_lem}')\n",
    "\n",
    "rec_logi_lem = recall_score(test_labels, y_val_pred_logi_Lem, average='macro')\n",
    "print(f'Recall (macro average) = {rec_logi_lem}')\n",
    "\n",
    "f1_micro_logi_lem = f1_score(test_labels, y_val_pred_logi_Lem, average='micro')\n",
    "print(f'F1 score (micro average) = {f1_micro_logi_lem}')\n",
    "\n",
    "f1_macro_logi_lem = f1_score(test_labels, y_val_pred_logi_Lem, average='macro')\n",
    "print(f'F1 score (macro average) = {f1_macro_logi_lem}')\n",
    "\n",
    "# We can get all of these with a per-class breakdown using classification_report:\n",
    "print(classification_report(test_labels, y_val_pred_logi_Lem))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c436562c-d8de-48ef-8424-9c240fc7e0ff",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression to non Lem set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d00854a4-29b1-45a1-8e11-c3d3b7a2ed5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the classifier\n",
    "logi_classifier = LogisticRegression()\n",
    "\n",
    "# Training the classifier\n",
    "logi_classifier.fit(X_train, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb7fc275-3dd9-48d9-ab3e-555ebf1079b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the classifier\n",
    "y_val_pred_logi = logi_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b0f81fd-2912-4e1b-943d-6dcf761c8568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.6591928251121076\n",
      "Precision (macro average) = 0.6231460532931121\n",
      "Recall (macro average) = 0.5385835740145629\n",
      "F1 score (micro average) = 0.6591928251121076\n",
      "F1 score (macro average) = 0.5520781122487368\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.52      0.57        62\n",
      "           1       0.56      0.23      0.33        39\n",
      "           2       0.68      0.87      0.76       122\n",
      "\n",
      "    accuracy                           0.66       223\n",
      "   macro avg       0.62      0.54      0.55       223\n",
      "weighted avg       0.64      0.66      0.63       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc_logi = accuracy_score(test_labels, y_val_pred_logi)\n",
    "print(f'Accuracy = {acc_logi}')\n",
    "\n",
    "prec_logi = precision_score(test_labels, y_val_pred_logi, average='macro')\n",
    "print(f'Precision (macro average) = {prec_logi}')\n",
    "\n",
    "rec_logi = recall_score(test_labels, y_val_pred_logi, average='macro')\n",
    "print(f'Recall (macro average) = {rec_logi}')\n",
    "\n",
    "f1_micro_logi = f1_score(test_labels, y_val_pred_logi, average='micro')\n",
    "print(f'F1 score (micro average) = {f1_micro_logi}')\n",
    "\n",
    "f1_macro_logi = f1_score(test_labels, y_val_pred_logi, average='macro')\n",
    "print(f'F1 score (macro average) = {f1_macro_logi}')\n",
    "\n",
    "# We can get all of these with a per-class breakdown using classification_report:\n",
    "print(classification_report(test_labels, y_val_pred_logi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24d7d2-6dc2-4362-81a6-4351956975a4",
   "metadata": {},
   "source": [
    "## Comparing Lem to Non Lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "618f457c-8673-4655-afd0-0f96e0b64d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# define the different metrics and their scores for bayes with lem\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1 Micro\", \"F1 Macro\"]\n",
    "bayes_lem = [acc_lem, prec_lem, rec_lem, f1_micro_lem, f1_macro_lem]\n",
    "\n",
    "# define their scores for Bayes non lem\n",
    "bayes_non_lem = [acc, prec, rec, f1_micro, f1_macro]\n",
    "\n",
    "# Logistic Regresion with Lemmatisation\n",
    "logi_lem = [acc_logi_lem, prec_logi_lem, rec_logi_lem, f1_micro_logi_lem, f1_macro_logi_lem]\n",
    "\n",
    "# Logistic Regresion sans Lemmatisation\n",
    "logi = [acc_logi, prec_logi, rec_logi, f1_micro_logi, f1_macro_logi]\n",
    "\n",
    "# set the width of the bars\n",
    "bar_width = 0.15\n",
    "\n",
    "# set the x-positions of the bars\n",
    "r1 = np.arange(len(metrics))\n",
    "r2 = [x + bar_width for x in r1]\n",
    "r3 = [x + bar_width for x in r2]\n",
    "r4 = [x + bar_width for x in r3]\n",
    "\n",
    "# create the bar plot\n",
    "plt.bar(r1, bayes_lem, color=\"tab:blue\", width=bar_width, edgecolor=\"black\", label=\"Naive Bayes with Lemmatisation\")\n",
    "plt.bar(r2, bayes_non_lem, color=\"tab:orange\", width=bar_width, edgecolor=\"black\", label=\"Naive Bayes without Lemmatisation\")\n",
    "plt.bar(r3, logi_lem, color=\"tab:green\", width=bar_width, edgecolor=\"black\", label=\"Logistic Regression with Lemmatisation\")\n",
    "plt.bar(r4, logi, color=\"tab:red\", width=bar_width, edgecolor=\"black\", label=\"Logistic Regression without Lemmatisation\")\n",
    "\n",
    "# add labels and title\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.xticks([r + bar_width*2 for r in range(len(metrics))], metrics)\n",
    "plt.title(\"Comparison of Model Metrics\")\n",
    "\n",
    "# set y-axis limits\n",
    "plt.ylim(0.5, 0.85)\n",
    "\n",
    "# add legend\n",
    "plt.legend()\n",
    "\n",
    "# show the plot\n",
    "plt.grid(axis=\"y\")\n",
    "plt.savefig(\"model_comparison.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b71c69-6548-4dbc-b617-c083c69ab029",
   "metadata": {},
   "source": [
    "## Identifying Common Themes/Topics associated with Positive/Negative Sentiment using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac12e80c-8b49-4340-aa3a-2fe7cb18e455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training dictionary\n",
    "train_documents_tok = [LemmaTokenizer()(doc) for doc in train_documents]\n",
    "train_dictionary = Dictionary(train_documents_tok)\n",
    "\n",
    "# create testing dictionary\n",
    "test_documents_tok = [LemmaTokenizer()(doc) for doc in test_documents]\n",
    "test_dictionary = Dictionary(test_documents_tok)\n",
    "\n",
    "# create bag of words\n",
    "train_corpus = [train_dictionary.doc2bow(doc) for doc in train_documents_tok]\n",
    "test_corpus = [test_dictionary.doc2bow(doc) for doc in test_documents_tok]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "840cef60-0e5a-48c3-9553-fedc4efd9e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the documents using the trained Naive Bayes classifier\n",
    "# y_val_pred_Lem = classifier_Lem.predict(X_test_Lem)\n",
    "\n",
    "# make predictions using the trained Naive Bayes model\n",
    "train_predictions = classifier_Lem.predict(X_train_Lem)\n",
    "test_predictions = classifier_Lem.predict(X_test_Lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "01b652c6-e9a4-4540-a1f7-19b16e6bacb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the index for each sentiment, so the LDA method can be trained to identify topics on positive data etc\n",
    "positive_train_docs = []\n",
    "neutral_train_docs = []\n",
    "negative_train_docs = []\n",
    "\n",
    "for i, val in enumerate(train_predictions):\n",
    "    if val == 2:\n",
    "        positive_train_docs.append(i)\n",
    "    elif val == 1:\n",
    "        neutral_train_docs.append(i)\n",
    "    elif val == 0:\n",
    "        negative_train_docs.append(i)\n",
    "        \n",
    "positive_test_docs = []\n",
    "neutral_test_docs = []\n",
    "negative_test_docs = []\n",
    "\n",
    "for i, val in enumerate(test_predictions):\n",
    "    if val == 2:\n",
    "        positive_test_docs.append(i)\n",
    "    elif val == 1:\n",
    "        neutral_test_docs.append(i)\n",
    "    elif val == 0:\n",
    "        negative_test_docs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "07d292de-ff62-4134-9af9-b1e48597147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the positive corpuses\n",
    "positive_train_corpus = [train_dictionary.doc2bow(train_documents_tok[i]) for i in positive_train_docs]\n",
    "positive_test_corpus = [test_dictionary.doc2bow(test_documents_tok[i]) for i in positive_test_docs]\n",
    "\n",
    "# Defining the negative corpuses\n",
    "negative_train_corpus = [train_dictionary.doc2bow(train_documents_tok[i]) for i in negative_train_docs]\n",
    "negative_test_corpus = [test_dictionary.doc2bow(test_documents_tok[i]) for i in negative_test_docs]\n",
    "\n",
    "# train LDA model for the positive corpus\n",
    "num_topics = 20 # number of topics to extract\n",
    "positive_lda_model = LdaModel(corpus=positive_train_corpus, num_topics=num_topics, id2word=train_dictionary, iterations=50, passes=20)\n",
    "\n",
    "# train LDA model for the negative corpus\n",
    "negative_lda_model = LdaModel(corpus=negative_train_corpus, num_topics=num_topics, id2word=train_dictionary, iterations=50, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0f756e75-85f3-4f85-94b3-9947e5ad3cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.036*\"$\" + 0.029*\"on\" + 0.021*\".\" + 0.015*\"a\" + 0.013*\"for\" + 0.011*\",\" + 0.010*\"day\" + 0.010*\"'s\" + 0.009*\"fda\" + 0.009*\"cancer\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.033*\"to\" + 0.021*\"$\" + 0.012*\"in\" + 0.010*\"with\" + 0.008*\"a\" + 0.007*\"lse\" + 0.007*\"share\" + 0.007*\"plc\" + 0.007*\"price\" + 0.007*\"bg\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.057*\".\" + 0.041*\"$\" + 0.025*\"a\" + 0.015*\"it\" + 0.013*\"of\" + 0.011*\"-\" + 0.011*\"at\" + 0.011*\"aapl\" + 0.009*\":\" + 0.009*\"be\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.036*\"$\" + 0.024*\".\" + 0.021*\"to\" + 0.018*\":\" + 0.016*\"in\" + 0.015*\"the\" + 0.014*\"http\" + 0.014*\"@\" + 0.010*\"stake\" + 0.010*\"and\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.028*\"inbev\" + 0.027*\"$\" + 0.027*\"sabmiller\" + 0.025*\"ab\" + 0.017*\",\" + 0.013*\":\" + 0.011*\"to\" + 0.010*\"for\" + 0.008*\"bp\" + 0.008*\"...\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.034*\"$\" + 0.025*\".\" + 0.022*\"to\" + 0.016*\"the\" + 0.013*\"up\" + 0.012*\"a\" + 0.011*\"after\" + 0.011*\"for\" + 0.009*\"i\" + 0.009*\"long\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.036*\"$\" + 0.016*\"for\" + 0.011*\"to\" + 0.011*\"from\" + 0.011*\":\" + 0.011*\"and\" + 0.011*\"is\" + 0.009*\"a\" + 0.009*\"http\" + 0.009*\"on\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.035*\"$\" + 0.023*\"a\" + 0.016*\".\" + 0.013*\",\" + 0.010*\":\" + 0.010*\"on\" + 0.007*\"breakout\" + 0.007*\"http\" + 0.007*\"of\" + 0.007*\"spy\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.050*\":\" + 0.034*\",\" + 0.022*\"$\" + 0.022*\"http\" + 0.011*\"at\" + 0.011*\"-\" + 0.010*\"on\" + 0.009*\"and\" + 0.007*\"'s\" + 0.007*\"...\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.042*\"$\" + 0.025*\".\" + 0.017*\":\" + 0.016*\"on\" + 0.013*\"http\" + 0.013*\"the\" + 0.012*\"and\" + 0.009*\"a\" + 0.008*\",\" + 0.008*\"it\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.092*\"$\" + 0.037*\":\" + 0.032*\"http\" + 0.014*\"and\" + 0.013*\"to\" + 0.008*\"a\" + 0.008*\"on\" + 0.008*\"@\" + 0.007*\"long\" + 0.007*\"fb\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.048*\"$\" + 0.024*\"a\" + 0.023*\".\" + 0.021*\",\" + 0.017*\":\" + 0.014*\"of\" + 0.014*\"#\" + 0.013*\"the\" + 0.013*\"http\" + 0.011*\"and\"\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.018*\"a\" + 0.013*\"sale\" + 0.009*\"$\" + 0.009*\",\" + 0.009*\"to\" + 0.009*\"#\" + 0.005*\":\" + 0.005*\"in\" + 0.005*\".\" + 0.005*\"stock\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.079*\"$\" + 0.041*\".\" + 0.023*\":\" + 0.015*\"a\" + 0.014*\",\" + 0.013*\"close\" + 0.012*\"call\" + 0.011*\"http\" + 0.011*\"aapl\" + 0.011*\"%\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.036*\"$\" + 0.017*\"of\" + 0.017*\"the\" + 0.017*\":\" + 0.015*\"to\" + 0.014*\".\" + 0.013*\",\" + 0.013*\"http\" + 0.013*\"-\" + 0.013*\"@\"\n",
      "\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.046*\"$\" + 0.029*\"to\" + 0.018*\".\" + 0.015*\"a\" + 0.015*\"'s\" + 0.013*\":\" + 0.013*\"in\" + 0.013*\"for\" + 0.012*\"http\" + 0.010*\"%\"\n",
      "\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.051*\"$\" + 0.043*\":\" + 0.032*\"http\" + 0.026*\"a\" + 0.020*\",\" + 0.014*\"of\" + 0.010*\"up\" + 0.008*\"in\" + 0.008*\"to\" + 0.006*\"for\"\n",
      "\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.045*\"$\" + 0.035*\",\" + 0.028*\".\" + 0.020*\")\" + 0.018*\"(\" + 0.016*\"to\" + 0.014*\"and\" + 0.013*\"out\" + 0.012*\"up\" + 0.012*\"!\"\n",
      "\n",
      "\n",
      "Topic: 18 \n",
      "Words: 0.047*\"$\" + 0.035*\"to\" + 0.022*\"for\" + 0.019*\"billion\" + 0.015*\"deal\" + 0.014*\"buy\" + 0.014*\":\" + 0.013*\"shire\" + 0.011*\"from\" + 0.011*\"the\"\n",
      "\n",
      "\n",
      "Topic: 19 \n",
      "Words: 0.028*\"$\" + 0.015*\"very\" + 0.012*\":\" + 0.012*\",\" + 0.009*\"and\" + 0.009*\"i\" + 0.006*\"high\" + 0.006*\"http\" + 0.006*\"this\" + 0.006*\".\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in positive_lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "5b33b8ea-d4ec-4a89-b6bb-5dc338651efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.017*\"$\" + 0.013*\"fall\" + 0.013*\"in\" + 0.009*\"?\" + 0.009*\".\" + 0.009*\"a\" + 0.005*\"of\" + 0.005*\"share\" + 0.005*\"to\" + 0.005*\"ready\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.019*\"on\" + 0.015*\"price\" + 0.014*\"$\" + 0.011*\"lower\" + 0.011*\"...\" + 0.008*\",\" + 0.008*\"'s\" + 0.008*\".\" + 0.008*\"drop\" + 0.008*\"hit\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.014*\",\" + 0.014*\":\" + 0.011*\"$\" + 0.009*\"a\" + 0.009*\"http\" + 0.009*\"dma\" + 0.009*\"support\" + 0.006*\"spy\" + 0.005*\"to\" + 0.005*\"@\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.009*\"ntap\" + 0.009*\"market\" + 0.009*\"think\" + 0.009*\"price\" + 0.009*\"cut\" + 0.008*\"@\" + 0.008*\"will\" + 0.007*\".\" + 0.006*\",\" + 0.006*\"$\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.027*\",\" + 0.023*\"$\" + 0.017*\"the\" + 0.013*\"to\" + 0.010*\"%\" + 0.010*\"is\" + 0.007*\".\" + 0.007*\"...\" + 0.007*\"only\" + 0.007*\"weak\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.021*\"$\" + 0.019*\"on\" + 0.017*\":\" + 0.011*\"http\" + 0.008*\"%\" + 0.008*\"down\" + 0.008*\"a\" + 0.008*\"juniper\" + 0.008*\"csco\" + 0.008*\"q1\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.048*\"$\" + 0.028*\".\" + 0.020*\":\" + 0.017*\"short\" + 0.017*\"to\" + 0.014*\"http\" + 0.014*\",\" + 0.011*\"a\" + 0.009*\"on\" + 0.009*\"%\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.061*\"$\" + 0.028*\",\" + 0.022*\":\" + 0.019*\"to\" + 0.018*\"http\" + 0.015*\"a\" + 0.011*\"...\" + 0.010*\"short\" + 0.008*\"and\" + 0.008*\"from\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.010*\"sale\" + 0.010*\"for\" + 0.006*\"$\" + 0.005*\"comparative\" + 0.005*\"'\" + 0.005*\"rival\" + 0.005*\"leave\" + 0.005*\"taste\" + 0.005*\"diageo\" + 0.005*\"and\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.089*\"$\" + 0.040*\".\" + 0.018*\"a\" + 0.013*\"to\" + 0.013*\":\" + 0.012*\"the\" + 0.011*\",\" + 0.011*\"#\" + 0.009*\"aapl\" + 0.007*\"of\"\n",
      "\n",
      "\n",
      "Topic: 10 \n",
      "Words: 0.026*\".\" + 0.023*\"$\" + 0.013*\"the\" + 0.010*\"by\" + 0.010*\"a\" + 0.010*\"and\" + 0.007*\":\" + 0.007*\"ba\" + 0.007*\"u\" + 0.007*\"of\"\n",
      "\n",
      "\n",
      "Topic: 11 \n",
      "Words: 0.015*\"$\" + 0.011*\"of\" + 0.011*\"share\" + 0.008*\"http\" + 0.008*\":\" + 0.008*\"hsbc\" + 0.008*\"by\" + 0.008*\";\" + 0.008*\"and\" + 0.008*\"to\"\n",
      "\n",
      "\n",
      "Topic: 12 \n",
      "Words: 0.032*\"$\" + 0.018*\".\" + 0.015*\",\" + 0.012*\"the\" + 0.011*\":\" + 0.011*\"http\" + 0.010*\"tsla\" + 0.009*\"day\" + 0.009*\"to\" + 0.006*\"in\"\n",
      "\n",
      "\n",
      "Topic: 13 \n",
      "Words: 0.046*\"$\" + 0.023*\".\" + 0.014*\"the\" + 0.013*\"#\" + 0.013*\"is\" + 0.010*\"still\" + 0.010*\"in\" + 0.009*\"and\" + 0.008*\"for\" + 0.007*\":\"\n",
      "\n",
      "\n",
      "Topic: 14 \n",
      "Words: 0.056*\"$\" + 0.018*\".\" + 0.017*\"to\" + 0.016*\":\" + 0.015*\"a\" + 0.013*\"http\" + 0.013*\"-\" + 0.012*\"on\" + 0.009*\"from\" + 0.008*\",\"\n",
      "\n",
      "\n",
      "Topic: 15 \n",
      "Words: 0.016*\"$\" + 0.012*\":\" + 0.012*\"it\" + 0.012*\"a\" + 0.012*\">\" + 0.012*\"sell\" + 0.008*\"hit\" + 0.008*\"'s\" + 0.008*\"after\" + 0.008*\"for\"\n",
      "\n",
      "\n",
      "Topic: 16 \n",
      "Words: 0.032*\",\" + 0.021*\"$\" + 0.018*\"to\" + 0.014*\"http\" + 0.014*\":\" + 0.011*\"in\" + 0.011*\"short\" + 0.007*\"on\" + 0.007*\"price\" + 0.007*\"that\"\n",
      "\n",
      "\n",
      "Topic: 17 \n",
      "Words: 0.050*\"tsla\" + 0.044*\":\" + 0.041*\"recall\" + 0.041*\"x\" + 0.039*\"$\" + 0.038*\"http\" + 0.036*\"model\" + 0.027*\"tesla\" + 0.022*\"2,700\" + 0.017*\"suv\"\n",
      "\n",
      "\n",
      "Topic: 18 \n",
      "Words: 0.024*\"$\" + 0.017*\".\" + 0.011*\"the\" + 0.010*\",\" + 0.007*\"i\" + 0.007*\"around\" + 0.007*\"but\" + 0.007*\"support\" + 0.007*\"can\" + 0.007*\"back\"\n",
      "\n",
      "\n",
      "Topic: 19 \n",
      "Words: 0.039*\"$\" + 0.013*\"-\" + 0.009*\"the\" + 0.009*\"a\" + 0.009*\"up\" + 0.009*\"sbux\" + 0.008*\"spy\" + 0.007*\".\" + 0.006*\"out\" + 0.006*\"to\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in negative_lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic ))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "0baaa113-0d4c-4194-a9f4-ed8711921621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', 'aapl', 'long', '630.91']\n",
      "$: 1\n",
      "630.91: 1\n",
      "aapl: 1\n",
      "long: 1\n"
     ]
    }
   ],
   "source": [
    "# Testing on unseen positive data    \n",
    "print(test_documents_tok[positive_test_docs[0]])\n",
    "\n",
    "# Data preprocessing step for the unseen document - It is the same preprocessing we have performed for the training data\n",
    "positive_bow_vector = test_dictionary.doc2bow(test_documents_tok[positive_test_docs[0]])\n",
    "\n",
    "for idx, count in positive_bow_vector:\n",
    "    print(f'{test_dictionary[idx]}: {count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2d428ef6-b03f-4cad-a4c2-2aa22f8329ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$', 'fb', 'i', 'guess', 'they', 'want', 'it', 'down', 'look', 'at', 'the', 'those', 'sell', 'order']\n",
      "$: 1\n",
      "down: 1\n",
      "fb: 1\n",
      "the: 1\n",
      "at: 1\n",
      "guess: 1\n",
      "i: 1\n",
      "it: 1\n",
      "look: 1\n",
      "order: 1\n",
      "sell: 1\n",
      "they: 1\n",
      "those: 1\n",
      "want: 1\n"
     ]
    }
   ],
   "source": [
    "# Testing on unseen negative data    \n",
    "print(test_documents_tok[negative_test_docs[0]])\n",
    "\n",
    "# Data preprocessing step for the unseen document - It is the same preprocessing we have performed for the training data\n",
    "negative_bow_vector = test_dictionary.doc2bow(test_documents_tok[negative_test_docs[0]])\n",
    "\n",
    "for idx, count in negative_bow_vector:\n",
    "    print(f'{test_dictionary[idx]}: {count}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
